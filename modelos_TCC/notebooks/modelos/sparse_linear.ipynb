{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sparse Autoenconder - Vers√£o Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from utils.load_mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.load_mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseLinearAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, sparsity_coeff=0.01):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.sparsity_coeff = sparsity_coeff\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "    def loss(self, x, reconstructed, latent):\n",
    "        mse_loss = nn.MSELoss()(reconstructed, x)\n",
    "        l1_loss = torch.norm(latent, p=1)\n",
    "        return mse_loss + self.sparsity_coeff * l1_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs=50, lr=1e-3):\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            x, _ = batch\n",
    "            x = x.view(x.size(0), -1).to(device)\n",
    "            reconstructed, latent = model(x)\n",
    "            loss = model.loss(x, reconstructed, latent)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0669\n",
      "Epoch [2/50], Loss: 0.0685\n",
      "Epoch [3/50], Loss: 0.0682\n",
      "Epoch [4/50], Loss: 0.0670\n",
      "Epoch [5/50], Loss: 0.0631\n",
      "Epoch [6/50], Loss: 0.0652\n",
      "Epoch [7/50], Loss: 0.0659\n",
      "Epoch [8/50], Loss: 0.0709\n",
      "Epoch [9/50], Loss: 0.0616\n",
      "Epoch [10/50], Loss: 0.0678\n",
      "Epoch [11/50], Loss: 0.0653\n",
      "Epoch [12/50], Loss: 0.0624\n",
      "Epoch [13/50], Loss: 0.0660\n",
      "Epoch [14/50], Loss: 0.0705\n",
      "Epoch [15/50], Loss: 0.0658\n",
      "Epoch [16/50], Loss: 0.0708\n",
      "Epoch [17/50], Loss: 0.0653\n",
      "Epoch [18/50], Loss: 0.0672\n",
      "Epoch [19/50], Loss: 0.0608\n",
      "Epoch [20/50], Loss: 0.0640\n",
      "Epoch [21/50], Loss: 0.0675\n",
      "Epoch [22/50], Loss: 0.0772\n",
      "Epoch [23/50], Loss: 0.0663\n",
      "Epoch [24/50], Loss: 0.0659\n",
      "Epoch [25/50], Loss: 0.0656\n",
      "Epoch [26/50], Loss: 0.0663\n",
      "Epoch [27/50], Loss: 0.0709\n",
      "Epoch [28/50], Loss: 0.0620\n",
      "Epoch [29/50], Loss: 0.0728\n",
      "Epoch [30/50], Loss: 0.0672\n",
      "Epoch [31/50], Loss: 0.0692\n",
      "Epoch [32/50], Loss: 0.0711\n",
      "Epoch [33/50], Loss: 0.0686\n",
      "Epoch [34/50], Loss: 0.0725\n",
      "Epoch [35/50], Loss: 0.0639\n",
      "Epoch [36/50], Loss: 0.0666\n",
      "Epoch [37/50], Loss: 0.0701\n",
      "Epoch [38/50], Loss: 0.0663\n",
      "Epoch [39/50], Loss: 0.0706\n",
      "Epoch [40/50], Loss: 0.0599\n",
      "Epoch [41/50], Loss: 0.0659\n",
      "Epoch [42/50], Loss: 0.0686\n",
      "Epoch [43/50], Loss: 0.0746\n",
      "Epoch [44/50], Loss: 0.0662\n",
      "Epoch [45/50], Loss: 0.0714\n",
      "Epoch [46/50], Loss: 0.0699\n",
      "Epoch [47/50], Loss: 0.0603\n",
      "Epoch [48/50], Loss: 0.0650\n",
      "Epoch [49/50], Loss: 0.0695\n",
      "Epoch [50/50], Loss: 0.0684\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_loader = load_mnist()\n",
    "    model = SparseLinearAE(28*28, 32)\n",
    "    train(model, train_loader)\n",
    "    torch.save(model.state_dict(), 'tests/sparse_linear.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
