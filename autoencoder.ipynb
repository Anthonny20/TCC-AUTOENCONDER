{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building AE using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start building a very simple autoencoder for the MNIST dataset using Pytorch. The MNIST dataset is eidely used for becnhmark dataset in machine learning and computer vision. It consists of a collection of 28x28 grayscale images of handwritten digits (0-9). The dataset is divided into a training set with 60.000 images and a test set with 10.000 images. It's often employed to evaluate the perfomance of various neural network architectures and algorithms for digit recognition tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will import libraries like torch, numpy, and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import sampler\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando e Preparando o Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação: Converte para o tensor e normaliza\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Carregar MNIST\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o Autoencoder usando Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        #Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "\n",
    "        #Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()    # Para normalizar saída entre 0 e 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded  = self.encoder(x)\n",
    "        decoded  = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Autoencoder(latent_dim=16).to(device)\n",
    "\n",
    "criterion = nn.MSELoss() # Usamos erro quadrático médio\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinando o Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 1/20, Loss: 0.9253655924980067\n",
      "Época 2/20, Loss: 0.9253647869456806\n",
      "Época 3/20, Loss: 0.925366462230174\n",
      "Época 4/20, Loss: 0.9253684303907952\n",
      "Época 5/20, Loss: 0.9253702311754735\n",
      "Época 6/20, Loss: 0.9253676271896119\n",
      "Época 7/20, Loss: 0.9253701251834187\n",
      "Época 8/20, Loss: 0.9253684921559494\n",
      "Época 9/20, Loss: 0.9253708082221465\n",
      "Época 10/20, Loss: 0.9253715102606491\n",
      "Época 11/20, Loss: 0.9253697082050828\n",
      "Época 12/20, Loss: 0.9253710921385141\n",
      "Época 13/20, Loss: 0.9253731702309428\n",
      "Época 14/20, Loss: 0.9253694587933229\n",
      "Época 15/20, Loss: 0.9253674183191776\n",
      "Época 16/20, Loss: 0.925366715009787\n",
      "Época 17/20, Loss: 0.9253690126481087\n",
      "Época 18/20, Loss: 0.9253699523426576\n",
      "Época 19/20, Loss: 0.9253658905212305\n",
      "Época 20/20, Loss: 0.9253667473538852\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for data in trainloader:\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Época {epoch+1}/{num_epochs}, Loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#Converter para CPU para visualização\u001b[39;00m\n\u001b[0;32m      7\u001b[0m test_images \u001b[38;5;241m=\u001b[39m test_images\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m----> 8\u001b[0m reconstructed \u001b[38;5;241m=\u001b[39m \u001b[43mreconstructed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_images, _ = next(iter(testloader))\n",
    "test_images = test_images.view(test_images.size(0), -1).to(device)\n",
    "reconstructed = model(test_images)\n",
    "\n",
    "#Converter para CPU para visualização\n",
    "test_images = test_images.cpu().detach().numpy()\n",
    "reconstructed = reconstructed.cpu().detach.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando a recosntrução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplot(2, 10, figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    axes[0, i].imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].imshow(reconstructed[i].reshape(28, 28), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando MSE E SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = np.mean((test_images - reconstructed) ** 2)\n",
    "ssim_value = ssim(test_images[0].reshape(28, 28), reconstructed[0].reshape(28, 28))\n",
    "\n",
    "print(f\"MSE: {mse:.6f}\")\n",
    "print(f\"SSIM: {ssim_value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando Diferentes Configurações do Espaço Latente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variando latent_dim para 8, 16, 32, 64 e comparar os resultados\n",
    "for latent_dim in [8, 16, 32, 64]:\n",
    "    model = Autoencoder(latent_dim=latent_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Treinando para latent_dim={latent_dim}...\")\n",
    "for epoch in range(10):\n",
    "    for data in trainloader:\n",
    "        inputs,_ = data\n",
    "        inputs = inputs.view(inputs.size(0), -1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
