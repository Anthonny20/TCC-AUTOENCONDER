{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building AE using Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start building a very simple autoencoder for the MNIST dataset using Pytorch. The MNIST dataset is eidely used for becnhmark dataset in machine learning and computer vision. It consists of a collection of 28x28 grayscale images of handwritten digits (0-9). The dataset is divided into a training set with 60.000 images and a test set with 10.000 images. It's often employed to evaluate the perfomance of various neural network architectures and algorithms for digit recognition tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we will import libraries like torch, numpy, and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import sampler\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we'll set some hyperparameter like learning rate, batch size, number of epochs and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 20\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're downloading the MNIST dataset and setting the training and testing data loader with batch size of 256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders_mnist(batch_size, num_workers=0,\n",
    "                          train_transforms=None, test_transforms=None):\n",
    "    if train_transforms is None:\n",
    "        train_transforms = transforms.ToTensor()\n",
    "    if test_transforms is None:\n",
    "        test_transforms = transforms.ToTensor()\n",
    "\n",
    "    train_dataset = datasets.MNIST(root='data',\n",
    "                                   train=True,\n",
    "                                   transform=train_transforms, download=True)\n",
    "    valid_dataset = datasets.MNIST(root='data',\n",
    "                                   train=True,\n",
    "                                   transform=test_transforms)\n",
    "    test_dataset = datasets.MNIST(root='data',\n",
    "                                  train=False,\n",
    "                                  transform=test_transforms)\n",
    "    train_loader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=True)\n",
    "    valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=True)\n",
    "    test_loader  = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              num_workers=num_workers,\n",
    "                              shuffle=False)\n",
    "    \n",
    "    return train_loader,valid_loader,  test_loader\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_mnist(batch_size=BATCH_SIZE, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the image batch dimensions and image label dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:\n",
      "\n",
      "Image batch dimensions: torch.Size([256, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([256])\n",
      "tensor([8, 2, 8, 3, 4, 4, 1, 9, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "#Checking the dataset\n",
    "print('Training Set:\\n')\n",
    "for images,labels, in train_loader:\n",
    "    print('Image batch dimensions:', images.size())\n",
    "    print('Image label dimensions:', labels.size())\n",
    "    print(labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to develop the model. The encoder uses four convolution layers with leaky relu as activation. The decoder has four transpose convolution layers and a trimming layer to get the generated image in (28, 28) dimension,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, stride=(1,1), kernel_size=(3, 3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(32, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(64, 64, stride=(2, 2), kernel_size=(3, 3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Conv2d(64, 64, stride=(1, 1), kernel_size=(3, 3), padding=1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3136, 2)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            torch.nn.Linear(2, 3136),\n",
    "            torch.reshape(-1, 64, 7, 7),\n",
    "            nn.ConvTranspose2d(64, 64, stride=(1, 1),\n",
    "                               kernel_size=(3, 3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(64, 64, stride=(2, 2),\n",
    "                               kernel_size=(3, 3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(64, 32, stride=(2, 2),\n",
    "                               kernel_size=(3, 3), padding=0),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.ConvTranspose2d(32, 1, stride=(1, 1),\n",
    "                               kernel_size=(3, 3), padding=0),\n",
    "                               torch.trim\n",
    "\n",
    "\n",
    "        )\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
